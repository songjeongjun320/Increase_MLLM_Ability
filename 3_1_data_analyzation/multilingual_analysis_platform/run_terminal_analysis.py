#!/usr/bin/env python3
"""
Terminal-based Model Comparison Analysis

Simple script to compare two models without browser interface.

module load cuda-12.6.1-gcc-12.1.0

"""

import sys
import os
from pathlib import Path

# Add the platform to the Python path
platform_dir = Path(__file__).parent
sys.path.insert(0, str(platform_dir))

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import warnings
import logging
import os

# Suppress warnings and logs
warnings.filterwarnings('ignore')
logging.getLogger('matplotlib').setLevel(logging.WARNING)
logging.getLogger('PIL').setLevel(logging.WARNING)
logging.getLogger('transformers').setLevel(logging.WARNING)
logging.getLogger('sentence_transformers').setLevel(logging.WARNING)
logging.getLogger('torch').setLevel(logging.WARNING)

# Suppress matplotlib font warnings
logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

from core.sentence_embedding import SentenceEmbeddingAnalyzer
from core.attention_analysis import AttentionAnalyzer
from core.confidence_analysis import ConfidenceAnalyzer
from utils.comparison_utils import ModelComparisonSuite
from visualization.embedding_plots import EmbeddingVisualizer
from visualization.confidence_plots import ConfidenceVisualizer

# ============================================================================
# ğŸ”§ USER CONFIGURATION - ì—¬ê¸°ì„œ ì„¤ì •í•˜ì„¸ìš”!
# ============================================================================

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
BASE_MODEL_PATH = "/scratch/jsong132/Increase_MLLM_Ability/Base_Models/llama-3.2-3b-pt"  # ë² ì´ìŠ¤ ëª¨ë¸
TRAINING_MODEL_PATH = "/scratch/jsong132/Increase_MLLM_Ability/5_training/finetune_org/merged_models/llama-tow-allenai-merged"

# ë¶„ì„í•  ë¬¸ì¥ë“¤ (ì˜ì–´-í•œêµ­ì–´ ìŒ)
TEST_SENTENCES = [
    # Questions which model could get an answer in eng, but not in kor.
    ("An engineer is using a computer to design a bridge. Which test is the most important for safety purposes?", "ì—”ì§€ë‹ˆì–´ê°€ ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ êµëŸ‰ì„ ì„¤ê³„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ˆì „ì„ ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ í…ŒìŠ¤íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"),
    ("Phillip was making hot tea. When he poured the hot water into a glass, the glass broke. Which is the most likely reason the glass broke?", "ì§€í˜„ì€ ëœ¨ê±°ìš´ ì°¨ë¥¼ ë§Œë“¤ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ê°€ ëœ¨ê±°ìš´ ë¬¼ì„ ìœ ë¦¬ì”ì— ë¶€ì—ˆì„ ë•Œ ìœ ë¦¬ì”ì´ ê¹¨ì¡ŒìŠµë‹ˆë‹¤. ìœ ë¦¬ì”ì´ ê¹¨ì§„ ì´ìœ ë¡œ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ê²ƒì€ ë¬´ì—‡ì¼ê¹Œìš”?"),
    ("A 20 N object is placed on a surface and starts to slide. What is the most likely reason the object begins to move?", "20Nì˜ ë¬¼ì²´ê°€ í‘œë©´ ìœ„ì— ë†“ì¸ í›„ ë¯¸ë„ëŸ¬ì§€ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ë¬¼ì²´ê°€ ì›€ì§ì´ê¸° ì‹œì‘í•˜ëŠ” ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"),
    ("What is most likely the first step for students to do for a recycling project?", "í•™ìƒë“¤ì´ ì¬í™œìš© í”„ë¡œì íŠ¸ë¥¼ ìœ„í•´ ê°€ì¥ ë¨¼ì € í•´ì•¼ í•  ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?"),
    # Questions which model could get an answer both lang.
    ("Which has the greatest effect on wind speed?", "í’ì†ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?"),
    ("Why does a town in the desert rarely experience early morning fog as compared to a town along the coast?","ì‚¬ë§‰ì— ìˆëŠ” ë§ˆì„ì´ í•´ì•ˆê°€ì— ìˆëŠ” ë§ˆì„ì— ë¹„í•´ ì´ë¥¸ ì•„ì¹¨ì— ì•ˆê°œê°€ ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"),
    ("A student mixed 25 grams of salt into 1,000 grams of water. What is the mass of the saltwater mixture?","í•œ í•™ìƒì´ ì†Œê¸ˆ 25ê·¸ë¨ì„ ë¬¼ 1,000ê·¸ë¨ì— ì„ì—ˆìŠµë‹ˆë‹¤. ì†Œê¸ˆë¬¼ í˜¼í•©ë¬¼ì˜ ì§ˆëŸ‰ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?"),
    ("One characteristic that is unique to water is that it","ë¬¼ì˜ ë…íŠ¹í•œ íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.")
]

# ë¶„ì„ ì˜µì…˜
ENABLE_ATTENTION_ANALYSIS = True
ENABLE_CONFIDENCE_ANALYSIS = True
SAVE_RESULTS = True

# ============================================================================

def setup_korean_font():
    """Setup Korean font for matplotlib to display Korean text properly."""
    import matplotlib.pyplot as plt  # Import at the beginning
    
    try:
        # Suppress all font-related warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # Try to find Korean fonts quietly
            korean_font_names = [
                'NanumGothic', 'Nanum Gothic', 'NanumBarunGothic', 'NanumBarunGothicOTF',
                'Malgun Gothic', 'Gulim', 'Dotum', 'Batang', 'Gungsuh', 'AppleGothic',
                'Noto Sans CJK KR', 'Source Han Sans KR', 'Roboto', 'Arial Unicode MS'
            ]
            
            available_fonts = [f.name for f in fm.fontManager.ttflist]
            print(f"ğŸ” Available fonts: {len(available_fonts)} total")

            found_font = None
            for font_name in korean_font_names:
                if font_name in available_fonts:
                    found_font = font_name
                    break

            if found_font:
                plt.rcParams['font.family'] = found_font
                plt.rcParams['font.size'] = 10
                print(f"ğŸ”¤ Korean font: {found_font}")
            else:
                # Use system fallback fonts
                plt.rcParams['font.family'] = ['Arial Unicode MS', 'AppleGothic', 'Malgun Gothic', 'DejaVu Sans', 'sans-serif']
                plt.rcParams['font.size'] = 10
                print("ğŸ”¤ Korean font: System font fallback")

    except Exception as e:
        print(f"ğŸ”¤ Font setup failed: {e}")
        # Final fallback
        plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
        plt.rcParams['font.size'] = 10

    # Additional matplotlib settings for better Korean support
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.autolayout'] = True
    
    print(f"ğŸ”¤ Final font family: {plt.rcParams['font.family']}")

def print_header():
    """Print analysis header."""
    print("ğŸŒ Multilingual Model Comparison Analysis")
    print("=" * 60)
    print(f"ğŸ“Š Base Model: {BASE_MODEL_PATH}")
    print(f"ğŸ¯ Training Model: {TRAINING_MODEL_PATH}")
    print(f"ğŸ“ Test Sentences: {len(TEST_SENTENCES)} pairs")
    print("=" * 60)
    print("\nğŸ“ Sentence Index Reference:")
    for i, (en, ko) in enumerate(TEST_SENTENCES):
        print(f"   [{i*2}] {en}")
        print(f"   [{i*2+1}] {ko}")
    print("=" * 60)

def save_embedding_visualizations(results):
    """Generate and save comprehensive embedding visualizations."""
    try:
        # Initialize Korean font manager first
        from utils.font_manager import setup_korean_fonts
        setup_korean_fonts()

        # Create output directory
        output_dir = platform_dir / "outputs" / "terminal_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)

        # Initialize embedding analyzer and visualizer
        embedding_analyzer = SentenceEmbeddingAnalyzer()
        visualizer = EmbeddingVisualizer()

        # Prepare text and language data with proper encoding
        texts = []
        languages = []
        for en, ko in TEST_SENTENCES:
            # Ensure proper UTF-8 encoding for Korean text
            texts.extend([en, ko.encode('utf-8').decode('utf-8')])
            languages.extend(['en', 'ko'])

        # Generate embeddings
        embedding_result = embedding_analyzer.generate_embeddings(texts, languages)
        embeddings = embedding_result['embeddings']

        # Generate comprehensive visualizations
        plots_saved = 0
        total_plots = 0

        print(f"   ğŸ“Š Generating comprehensive visualizations...")

        # 2D Visualizations
        for method in ['pca', 'tsne', 'umap']:
            total_plots += 1
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    fig = visualizer.plot_embeddings_2d(
                        embeddings=embeddings, languages=languages, texts=texts,
                        method=method, interactive=False,
                        title=f"{method.upper()} - Sentence Embeddings"
                    )
                    plt.savefig(output_dir / f"{method}_embeddings_2d.png",
                               dpi=300, bbox_inches='tight',
                               facecolor='white', edgecolor='none')
                    plt.close()
                    plots_saved += 1
            except Exception as e:
                print(f"      âš ï¸ {method.upper()} 2D plot failed: {e}")

        # 3D Visualizations
        for method in ['pca', 'tsne', 'umap']:
            total_plots += 1
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    fig = visualizer.plot_embeddings_3d(
                        embeddings=embeddings, languages=languages, texts=texts,
                        method=method, interactive=False,
                        title=f"{method.upper()} - 3D Sentence Embeddings"
                    )
                    plt.savefig(output_dir / f"{method}_embeddings_3d.png",
                               dpi=300, bbox_inches='tight',
                               facecolor='white', edgecolor='none')
                    plt.close()
                    plots_saved += 1
            except Exception as e:
                print(f"      âš ï¸ {method.upper()} 3D plot failed: {e}")

        # Similarity Analysis
        total_plots += 1
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                similarity_matrix = embedding_result['similarity_matrix']
                fig = visualizer.plot_similarity_heatmap(
                    similarity_matrix=similarity_matrix, texts=texts, languages=languages,
                    interactive=False, title="Sentence Similarity Heatmap"
                )
                plt.savefig(output_dir / "similarity_heatmap.png",
                           dpi=300, bbox_inches='tight',
                           facecolor='white', edgecolor='none')
                plt.close()
                plots_saved += 1
        except Exception as e:
            print(f"      âš ï¸ Similarity heatmap failed: {e}")

        # Language Clustering Analysis
        total_plots += 1
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                cluster_result = embedding_analyzer.analyze_language_clusters(embeddings, languages)
                fig = visualizer.plot_clustering_analysis(
                    embeddings, languages, cluster_result,
                    title="Language Clustering Analysis"
                )
                plt.savefig(output_dir / "language_clustering.png",
                           dpi=300, bbox_inches='tight',
                           facecolor='white', edgecolor='none')
                plt.close()
                plots_saved += 1
        except Exception as e:
            print(f"      âš ï¸ Language clustering plot failed: {e}")

        # Cross-Language Performance
        total_plots += 1
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                cross_lang_result = embedding_analyzer.analyze_cross_language_performance(
                    embeddings, languages, texts
                )
                fig = visualizer.plot_cross_language_performance(
                    cross_lang_result, title="Cross-Language Performance"
                )
                plt.savefig(output_dir / "cross_language_performance.png",
                           dpi=300, bbox_inches='tight',
                           facecolor='white', edgecolor='none')
                plt.close()
                plots_saved += 1
        except Exception as e:
            print(f"      âš ï¸ Cross-language performance plot failed: {e}")

        print(f"   âœ… Saved {plots_saved}/{total_plots} visualizations")

    except Exception as e:
        print(f"   âŒ Visualization generation failed: {e}")
        raise

def save_confidence_visualizations(confidence_result):
    """Generate and save confidence analysis visualizations."""
    try:
        output_dir = platform_dir / "outputs" / "terminal_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)

        visualizer = ConfidenceVisualizer()

        # Generate entropy by position plot
        try:
            fig = visualizer.plot_entropy_by_position(
                confidence_result=confidence_result,
                interactive=False,
                title="Token-wise Confidence Analysis"
            )
            plt.savefig(output_dir / "confidence_entropy.png", dpi=300, bbox_inches='tight')
            plt.close()
            print(f"   âœ… Confidence plot saved: {output_dir / 'confidence_entropy.png'}")
        except Exception as e:
            print(f"   âš ï¸ Entropy plot failed: {e}")

        # Generate uncertainty heatmap if we have token-level data
        try:
            if 'confidence_measures' in confidence_result:
                measures = confidence_result['confidence_measures']
                if 'variance' in measures or 'entropy' in measures:
                    fig = visualizer.plot_confidence_heatmap(
                        confidence_result=confidence_result,
                        interactive=False,
                        title="Confidence Heatmap"
                    )
                    plt.savefig(output_dir / "confidence_heatmap.png", dpi=300, bbox_inches='tight')
                    plt.close()
                    print(f"   âœ… Confidence heatmap saved: {output_dir / 'confidence_heatmap.png'}")
        except Exception as e:
            print(f"   âš ï¸ Confidence heatmap failed: {e}")

    except Exception as e:
        print(f"   âŒ Confidence visualization failed: {e}")

def save_confidence_comparison(base_result, train_result):
    """Generate and save confidence comparison visualizations."""
    try:
        output_dir = platform_dir / "outputs" / "terminal_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)

        visualizer = ConfidenceVisualizer()

        # Generate side-by-side confidence comparison
        fig = visualizer.plot_confidence_comparison(
            base_result=base_result,
            training_result=train_result,
            interactive=False,
            title="Base vs Training Model Confidence Comparison"
        )
        plt.savefig(output_dir / "confidence_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        print(f"   âœ… Confidence comparison saved: {output_dir / 'confidence_comparison.png'}")

    except Exception as e:
        print(f"   âŒ Confidence comparison visualization failed: {e}")

def analyze_embedding_differences():
    """Analyze embedding differences between models."""
    print("\nğŸ“Š Running Sentence Embedding Analysis...")

    try:
        # Initialize comparison suite
        comparison_suite = ModelComparisonSuite()

        # Run comparison
        results = comparison_suite.compare_base_vs_training_models(
            base_model_path=BASE_MODEL_PATH,
            training_model_path=TRAINING_MODEL_PATH,
            test_sentences=TEST_SENTENCES
        )

        # Print results
        print("\nâœ… Embedding Analysis Results:")
        print("-" * 40)

        if 'cross_language_performance' in results:
            perf = results['cross_language_performance']
            print(f"   Base Model Accuracy: {perf['base_accuracy']:.3f}")
            print(f"   Training Model Accuracy: {perf['training_accuracy']:.3f}")
            print(f"   Improvement: {perf['improvement']:.3f} ({perf['improvement_percentage']:.1f}%)")

        if 'pair_similarities' in results:
            print(f"\nğŸ“ Sentence Pair Similarities:")
            pairs = results['pair_similarities']
            for i, (en, ko) in enumerate(TEST_SENTENCES):
                if i < len(pairs['base_similarities']) and i < len(pairs['training_similarities']):
                    base_sim = pairs['base_similarities'][i]
                    train_sim = pairs['training_similarities'][i]
                    improvement = train_sim - base_sim
                    print(f"   [{i*2}] \"{en}\" â†” [{i*2+1}] \"{ko}\"")
                    print(f"     Base: {base_sim:.3f} â†’ Training: {train_sim:.3f} ({improvement:+.3f})")

        # Generate and save visualizations
        print(f"\nğŸ¨ Generating Visualizations...")
        try:
            save_embedding_visualizations(results)
        except Exception as e:
            print(f"   âš ï¸ Visualization generation failed: {e}")

        return results

    except Exception as e:
        print(f"   âŒ Embedding analysis failed: {e}")
        return None

def analyze_attention_differences():
    """Analyze attention pattern differences."""
    if not ENABLE_ATTENTION_ANALYSIS:
        return None

    print("\nğŸ” Running Attention Analysis...")

    try:
        attention_analyzer = AttentionAnalyzer()

        # Analyze first sentence as example
        sample_text = TEST_SENTENCES[0][0]  # First English sentence

        # Base model attention
        base_attention = attention_analyzer.extract_attention_weights(
            model_name_or_path=BASE_MODEL_PATH,
            text=sample_text,
            model_type='base'
        )

        print(f"   âœ… Base Model Attention: {base_attention['num_layers']} layers, {base_attention['num_heads']} heads")

        # Training model attention (if path exists)
        if os.path.exists(TRAINING_MODEL_PATH):
            train_attention = attention_analyzer.extract_attention_weights(
                model_name_or_path=TRAINING_MODEL_PATH,
                text=sample_text,
                model_type='trained'
            )
            print(f"   âœ… Training Model Attention: {train_attention['num_layers']} layers, {train_attention['num_heads']} heads")

            # Compare patterns
            comparison = attention_analyzer.compare_attention_patterns(
                base_attention, train_attention
            )
            print(f"   ğŸ“Š Attention Similarity: {comparison.get('overall_similarity', 'N/A')}")
        else:
            print(f"   âš ï¸ Training model path not found: {TRAINING_MODEL_PATH}")

        return base_attention

    except Exception as e:
        print(f"   âŒ Attention analysis failed: {e}")
        return None

def analyze_confidence_differences():
    """Analyze confidence differences."""
    if not ENABLE_CONFIDENCE_ANALYSIS:
        return None

    print("\nğŸ“ˆ Running Confidence Analysis...")

    try:
        confidence_analyzer = ConfidenceAnalyzer()

        # Analyze first sentence
        sample_text = TEST_SENTENCES[0][0]

        # Base model confidence
        base_confidence = confidence_analyzer.analyze_prediction_confidence(
            model_name_or_path=BASE_MODEL_PATH,
            text=sample_text,
            model_type='base'
        )

        print(f"   âœ… Base Model Confidence analyzed for {base_confidence['sequence_length']} tokens")
        print(f"   ğŸ“Š Method: {base_confidence.get('method', 'logit_based')}")

        if 'confidence_measures' in base_confidence:
            measures = base_confidence['confidence_measures']
            if 'entropy' in measures:
                entropy_data = measures['entropy']
                print(f"     Mean Entropy: {entropy_data['mean_entropy']:.3f}")
                print(f"     Uncertainty: {entropy_data['uncertainty_classification']}")
                print(f"     Method: {entropy_data.get('method', 'standard')}")

        # Check if we have embedding-based uncertainty summary
        if 'summary' in base_confidence:
            summary = base_confidence['summary']
            print(f"     Overall Uncertainty: {summary['uncertainty_level']}")
            if 'high_uncertainty_positions' in summary:
                high_positions = summary['high_uncertainty_positions']
                if high_positions:
                    print(f"     High Uncertainty Positions: {high_positions}")

        # Generate confidence visualization
        try:
            save_confidence_visualizations(base_confidence)
        except Exception as e:
            print(f"   âš ï¸ Confidence visualization failed: {e}")

        # Training model confidence (if exists)
        train_confidence = None
        if os.path.exists(TRAINING_MODEL_PATH):
            try:
                train_confidence = confidence_analyzer.analyze_prediction_confidence(
                    model_name_or_path=TRAINING_MODEL_PATH,
                    text=sample_text,
                    model_type='trained'
                )
                print(f"   âœ… Training Model Confidence analyzed")

                if 'confidence_measures' in train_confidence:
                    measures = train_confidence['confidence_measures']
                    if 'entropy' in measures:
                        entropy_data = measures['entropy']
                        print(f"     Mean Entropy: {entropy_data['mean_entropy']:.3f}")
                        print(f"     Uncertainty: {entropy_data['uncertainty_classification']}")

                # Generate comparison visualization
                try:
                    save_confidence_comparison(base_confidence, train_confidence)
                except Exception as e:
                    print(f"   âš ï¸ Confidence comparison visualization failed: {e}")

            except Exception as e:
                print(f"   âŒ Training model confidence analysis failed: {e}")
        else:
            print(f"   âš ï¸ Training model path not found: {TRAINING_MODEL_PATH}")

        return base_confidence

    except Exception as e:
        print(f"   âŒ Confidence analysis failed: {e}")
        return None

def save_results_to_file(embedding_results, attention_results, confidence_results):
    """Save analysis results to file."""
    if not SAVE_RESULTS:
        return

    print("\nğŸ’¾ Saving Results...")

    try:
        output_dir = platform_dir / "outputs" / "terminal_analysis"
        output_dir.mkdir(parents=True, exist_ok=True)

        # Save embedding results
        if embedding_results:
            import json
            with open(output_dir / "embedding_comparison.json", "w", encoding="utf-8") as f:
                # Convert numpy arrays to lists for JSON serialization
                def convert_numpy(obj):
                    if isinstance(obj, np.ndarray):
                        return obj.tolist()
                    elif isinstance(obj, (np.floating, float)):
                        return float(obj)
                    elif isinstance(obj, (np.integer, int)):
                        return int(obj)
                    elif hasattr(obj, '__dict__'):
                        return str(obj)  # Convert complex objects to string
                    return obj

                # Create a safe copy of results without circular references
                safe_results = {}
                for key, value in embedding_results.items():
                    try:
                        converted = convert_numpy(value)
                        safe_results[key] = converted
                    except (TypeError, ValueError):
                        safe_results[key] = str(value)

                json.dump(safe_results, f, ensure_ascii=False, indent=2, default=str)
            print(f"   âœ… Embedding results saved to: {output_dir / 'embedding_comparison.json'}")

        # Save summary
        summary_file = output_dir / "analysis_summary.txt"
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write("Multilingual Model Comparison Summary\n")
            f.write("=" * 40 + "\n\n")
            f.write(f"Base Model: {BASE_MODEL_PATH}\n")
            f.write(f"Training Model: {TRAINING_MODEL_PATH}\n")
            f.write(f"Test Sentences: {len(TEST_SENTENCES)} pairs\n\n")

            if embedding_results and 'cross_language_performance' in embedding_results:
                perf = embedding_results['cross_language_performance']
                f.write(f"Cross-Language Performance:\n")
                f.write(f"  Base Accuracy: {perf['base_accuracy']:.3f}\n")
                f.write(f"  Training Accuracy: {perf['training_accuracy']:.3f}\n")
                f.write(f"  Improvement: {perf['improvement']:.3f} ({perf['improvement_percentage']:.1f}%)\n\n")

            f.write("Test Sentence Pairs:\n")
            for i, (en, ko) in enumerate(TEST_SENTENCES, 1):
                f.write(f"  {i}. \"{en}\" â†” \"{ko}\"\n")

        print(f"   âœ… Summary saved to: {summary_file}")

    except Exception as e:
        print(f"   âŒ Failed to save results: {e}")

def main():
    """Main analysis function."""
    # Setup Korean font first
    from utils.font_manager import setup_korean_fonts
    setup_korean_fonts()

    print_header()

    # Check if training model exists
    if not os.path.exists(TRAINING_MODEL_PATH) and TRAINING_MODEL_PATH != "/path/to/your/trained/model":
        print(f"\nâš ï¸ Warning: Training model path not found: {TRAINING_MODEL_PATH}")
        print("   Analysis will proceed with base model only.\n")

    # Run analyses
    embedding_results = analyze_embedding_differences()
    attention_results = analyze_attention_differences()
    confidence_results = analyze_confidence_differences()

    # Save results
    save_results_to_file(embedding_results, attention_results, confidence_results)

    # Summary
    print("\nğŸ“‹ Analysis Summary")
    print("=" * 40)
    print("âœ… Sentence embedding comparison completed")
    if ENABLE_ATTENTION_ANALYSIS:
        print("âœ… Attention pattern analysis completed")
    if ENABLE_CONFIDENCE_ANALYSIS:
        print("âœ… Confidence analysis completed")
    if SAVE_RESULTS:
        print("âœ… Results saved to outputs/terminal_analysis/")

    print("\nğŸ‰ Terminal analysis completed successfully!")

if __name__ == "__main__":
    main()