2025-08-23 15:06:06,902 - INFO - [__main__] - --- Starting GSM8K Evaluation for Model: Qwen2.5-7B-Instruct (/scratch/jsong132/Increase_MLLM_Ability/Base_Models/Qwen2.5-7B-Instruct) ---
2025-08-23 15:06:06,902 - INFO - [__main__] - Output directory: gsm8k_hrm8k_results/Qwen2.5-7B-Instruct
2025-08-23 15:06:06,902 - INFO - [__main__] - Results will be saved to: gsm8k_hrm8k_results/Qwen2.5-7B-Instruct/results_Qwen2.5-7B-Instruct.json
2025-08-23 15:06:06,902 - INFO - [__main__] - Raw generations will be saved to: gsm8k_hrm8k_results/Qwen2.5-7B-Instruct/raw_generations_Qwen2.5-7B-Instruct.json
2025-08-23 15:06:06,902 - INFO - [__main__] - Using Device: cuda, DType: torch.bfloat16
2025-08-23 15:06:06,902 - INFO - [__main__] - Quantization: Disabled
2025-08-23 15:06:06,902 - INFO - [__main__] - Loading tokenizer from: /scratch/jsong132/Increase_MLLM_Ability/Base_Models/Qwen2.5-7B-Instruct
2025-08-23 15:06:07,216 - INFO - [__main__] - Loading model /scratch/jsong132/Increase_MLLM_Ability/Base_Models/Qwen2.5-7B-Instruct...
2025-08-23 15:06:54,534 - INFO - [__main__] - Resizing model token embeddings from 152064 to 151665
2025-08-23 15:06:54,572 - INFO - [__main__] - No LoRA adapter path specified. Using base model directly.
2025-08-23 15:06:54,573 - INFO - [__main__] - Model and tokenizer loaded successfully.
2025-08-23 15:06:54,573 - INFO - [__main__] - Starting GSM8K inference loop...
2025-08-23 15:06:54,573 - INFO - [__main__] - Dataset size: 1319
