#!/usr/bin/env python3
"""
Advanced Augmentation Techniques for Korean ToW Data
ì¶”ê°€ ì¦ê°• ê¸°ë²•: êµ¬ë¬¸ ë³€í™˜, ë¬¸ì²´ ë³€ê²½, ë„ë©”ì¸ë³„ íŠ¹í™” ì¦ê°•
"""

import json
import re
import random
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict
import logging
from dataclasses import dataclass
import numpy as np

logger = logging.getLogger(__name__)

@dataclass
class DomainConfig:
    """ë„ë©”ì¸ë³„ ì¦ê°• ì„¤ì •"""
    domain_name: str
    specialized_vocab: Dict[str, List[str]]
    syntax_patterns: List[Tuple[str, str]]
    style_preferences: Dict[str, float]  # ë¬¸ì²´ ì„ í˜¸ë„

class AdvancedAugmentationEngine:
    """ê³ ê¸‰ ì¦ê°• ê¸°ë²• ì—”ì§„"""
    
    def __init__(self):
        self.initialize_syntactic_patterns()
        self.initialize_stylistic_patterns()
        self.initialize_domain_configs()
        self.initialize_mathematical_patterns()
    
    def initialize_syntactic_patterns(self):
        """êµ¬ë¬¸ ë³€í™˜ íŒ¨í„´ ì´ˆê¸°í™”"""
        
        # 1. ëŠ¥ë™/ìˆ˜ë™íƒœ ë³€í™˜
        self.voice_patterns = {
            'active_to_passive': [
                (r'(\w+)ê°€ (\w+)ì„ (\w+)í•œë‹¤', r'\2ì´ \1ì— ì˜í•´ \3ë˜ë‹¤'),
                (r'(\w+)ì´ (\w+)ë¥¼ (\w+)í•œë‹¤', r'\2ê°€ \1ì— ì˜í•´ \3ë˜ë‹¤'),
                (r'(\w+)ê°€ (\w+)ì„ (\w+)í–ˆë‹¤', r'\2ì´ \1ì— ì˜í•´ \3ë˜ì—ˆë‹¤'),
                (r'(\w+)ì´ (\w+)ë¥¼ (\w+)í–ˆë‹¤', r'\2ê°€ \1ì— ì˜í•´ \3ë˜ì—ˆë‹¤')
            ],
            'passive_to_active': [
                (r'(\w+)ì´ (\w+)ì— ì˜í•´ (\w+)ë˜ë‹¤', r'\2ê°€ \1ì„ \3í•œë‹¤'),
                (r'(\w+)ê°€ (\w+)ì— ì˜í•´ (\w+)ë˜ë‹¤', r'\2ì´ \1ë¥¼ \3í•œë‹¤'),
                (r'(\w+)ì´ (\w+)ì— ì˜í•´ (\w+)ë˜ì—ˆë‹¤', r'\2ê°€ \1ì„ \3í–ˆë‹¤'),
                (r'(\w+)ê°€ (\w+)ì— ì˜í•´ (\w+)ë˜ì—ˆë‹¤', r'\2ì´ \1ë¥¼ \3í–ˆë‹¤')
            ]
        }
        
        # 2. ë¬¸ì¥ ì„±ë¶„ ì¬ë°°ì—´
        self.constituent_reordering = {
            'sov_to_osv': [
                (r'(\w+ê°€|ì´) (\w+ì„|ë¥¼) (\w+ë‹¤)', r'\2 \1 \3'),
                (r'(\w+ëŠ”|ì€) (\w+ì„|ë¥¼) (\w+ë‹¤)', r'\2 \1 \3')
            ],
            'topic_fronting': [
                (r'(\w+ì—ì„œ) (\w+ê°€|ì´) (\w+ë‹¤)', r'\1ëŠ” \2 \3'),
                (r'(\w+ì—ê²Œ) (\w+ê°€|ì´) (\w+ë‹¤)', r'\1ëŠ” \2 \3')
            ],
            'temporal_fronting': [
                (r'(\w+ê°€|ì´) (ì–´ì œ|ì˜¤ëŠ˜|ë‚´ì¼) (\w+ë‹¤)', r'\2 \1 \3'),
                (r'(\w+ëŠ”|ì€) (ì–´ì œ|ì˜¤ëŠ˜|ë‚´ì¼) (\w+ë‹¤)', r'\2 \1 \3')
            ]
        }
        
        # 3. ì ˆ ë³€í™˜ (ë‹¨ìˆœì ˆ â†” ë³µì ˆ)
        self.clause_transformation = {
            'simple_to_complex': [
                (r'(\w+ë‹¤)\. (\w+ë‹¤)', r'\1ê³ , \2'),
                (r'(\w+ë‹¤)\. (\w+ë‹¤)', r'\1ì–´ì„œ \2'),
                (r'(\w+ë‹¤)\. (\w+ë‹¤)', r'\1ì§€ë§Œ \2')
            ],
            'complex_to_simple': [
                (r'(\w+)ê³ , (\w+ë‹¤)', r'\1ë‹¤. \2'),
                (r'(\w+)ì–´ì„œ (\w+ë‹¤)', r'\1ë‹¤. \2'),
                (r'(\w+)ì§€ë§Œ (\w+ë‹¤)', r'\1ë‹¤. í•˜ì§€ë§Œ \2')
            ],
            'relative_clause': [
                (r'(\w+)ëŠ” (\w+)ì´ë‹¤', r'\2ì¸ \1'),
                (r'(\w+)ì€ (\w+)ì´ë‹¤', r'\2ì¸ \1')
            ]
        }
    
    def initialize_stylistic_patterns(self):
        """ë¬¸ì²´ ë³€í™˜ íŒ¨í„´ ì´ˆê¸°í™”"""
        
        # 1. ê²©ì‹ë„ ë³€í™˜
        self.formality_patterns = {
            'formal_academic': {
                'ì´ë‹¤': 'ì´ë‹¤', 'í•œë‹¤': 'í•œë‹¤', 'ëœë‹¤': 'ëœë‹¤',
                # í•™ìˆ ì²´ íŠ¹ì§•
                'transforms': {
                    'ê·¸ë¦¬ê³ ': 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ': 'ê·¸ëŸ¬ë‚˜', 'ë•Œë¬¸ì—': 'ìœ¼ë¡œ ì¸í•´',
                    'ë§¤ìš°': 'ìƒë‹¹íˆ', 'ì •ë§': 'ì‹¤ë¡œ', 'ì•„ì£¼': 'ëŒ€ë‹¨íˆ'
                }
            },
            'semi_formal': {
                'ì´ë‹¤': 'ì…ë‹ˆë‹¤', 'í•œë‹¤': 'í•©ë‹ˆë‹¤', 'ëœë‹¤': 'ë©ë‹ˆë‹¤',
                'transforms': {
                    'ê·¸ë¦¬ê³ ': 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ': 'ê·¸ë ‡ì§€ë§Œ', 'ë•Œë¬¸ì—': 'ë•Œë¬¸ì…ë‹ˆë‹¤',
                    'ë§¤ìš°': 'ë§¤ìš°', 'ì •ë§': 'ì •ë§', 'ì•„ì£¼': 'ì•„ì£¼'
                }
            },
            'informal_polite': {
                'ì´ë‹¤': 'ì´ì—ìš”', 'í•œë‹¤': 'í•´ìš”', 'ëœë‹¤': 'ë¼ìš”',
                'transforms': {
                    'ê·¸ë¦¬ê³ ': 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ': 'ê·¸ëŸ°ë°', 'ë•Œë¬¸ì—': 'ë•Œë¬¸ì´ì—ìš”',
                    'ë§¤ìš°': 'ì•„ì£¼', 'ì •ë§': 'ì§„ì§œ', 'ì•„ì£¼': 'ì—„ì²­'
                }
            },
            'casual': {
                'ì´ë‹¤': 'ì´ì•¼', 'í•œë‹¤': 'í•´', 'ëœë‹¤': 'ë¼',
                'transforms': {
                    'ê·¸ë¦¬ê³ ': 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ': 'ê·¼ë°', 'ë•Œë¬¸ì—': 'ë•Œë¬¸ì´ì•¼',
                    'ë§¤ìš°': 'ì—„ì²­', 'ì •ë§': 'ì§„ì§œ', 'ì•„ì£¼': 'ì™„ì „'
                }
            }
        }
        
        # 2. ì–‘ìƒì„± í‘œí˜„ (modality)
        self.modality_patterns = {
            'certainty': {
                'high': ['ë°˜ë“œì‹œ', 'í™•ì‹¤íˆ', 'í‹€ë¦¼ì—†ì´', 'ë¶„ëª…íˆ'],
                'medium': ['ì•„ë§ˆ', 'ëŒ€ê°œ', 'ë³´í†µ', 'ì¼ë°˜ì ìœ¼ë¡œ'],
                'low': ['í˜¹ì‹œ', 'ì•„ë§ˆë„', 'ê°€ëŠ¥í•˜ë©´', 'ê²½ìš°ì— ë”°ë¼']
            },
            'possibility': {
                'high': ['í•  ìˆ˜ ìˆë‹¤', 'ê°€ëŠ¥í•˜ë‹¤', 'ë  ìˆ˜ ìˆë‹¤'],
                'medium': ['í• ì§€ë„ ëª¨ë¥¸ë‹¤', 'í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤'],
                'low': ['í•˜ê¸° ì–´ë µë‹¤', 'í˜ë“¤ ê²ƒ ê°™ë‹¤', 'ì–´ë ¤ìš¸ ê²ƒì´ë‹¤']
            },
            'necessity': {
                'strong': ['í•´ì•¼ í•œë‹¤', 'í•˜ì§€ ì•Šìœ¼ë©´ ì•ˆ ëœë‹¤', 'í•„ìˆ˜ë‹¤'],
                'medium': ['í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤', 'ê¶Œì¥ëœë‹¤', 'ë°”ëŒì§í•˜ë‹¤'],
                'weak': ['í•´ë„ ëœë‹¤', 'í•  ìˆ˜ë„ ìˆë‹¤', 'ê³ ë ¤í•´ë³¼ ë§Œí•˜ë‹¤']
            }
        }
        
        # 3. ë‹´í™” í‘œì§€ì–´ì™€ ì—°ê²°ì–´êµ¬
        self.discourse_markers = {
            'sequence': ['ë¨¼ì €', 'ë‹¤ìŒìœ¼ë¡œ', 'ê·¸ ë‹¤ìŒì—', 'ë§ˆì§€ë§‰ìœ¼ë¡œ', 'ê²°ë¡ ì ìœ¼ë¡œ'],
            'contrast': ['ë°˜ë©´ì—', 'í•œí¸', 'ê·¸ì™€ ë‹¬ë¦¬', 'ì˜¤íˆë ¤', 'ì—­ìœ¼ë¡œ'],
            'addition': ['ë˜í•œ', 'ë”ìš±ì´', 'ê²Œë‹¤ê°€', 'ë¿ë§Œ ì•„ë‹ˆë¼', 'ì•„ìš¸ëŸ¬'],
            'explanation': ['ì¦‰', 'ë‹¤ì‹œ ë§í•´', 'êµ¬ì²´ì ìœ¼ë¡œ', 'ì˜ˆë¥¼ ë“¤ì–´', 'ë°”ê¾¸ì–´ ë§í•˜ë©´'],
            'emphasis': ['íŠ¹íˆ', 'ë¬´ì—‡ë³´ë‹¤ë„', 'ì¤‘ìš”í•œ ê²ƒì€', 'ì£¼ëª©í•  ì ì€', 'ê°•ì¡°í•˜ë©´']
        }
    
    def initialize_domain_configs(self):
        """ë„ë©”ì¸ë³„ ì„¤ì • ì´ˆê¸°í™”"""
        
        # ìˆ˜í•™ ë„ë©”ì¸
        self.math_domain = DomainConfig(
            domain_name="mathematics",
            specialized_vocab={
                'ê³„ì‚°': ['ì—°ì‚°', 'ì‚°ì¶œ', 'ì‚°ì •'],
                'ë°©ë²•': ['ë°©ì‹', 'ê¸°ë²•', 'ì ˆì°¨', 'ì•Œê³ ë¦¬ì¦˜'],
                'ê²°ê³¼': ['ë‹µ', 'í•´', 'ê°’', 'ê²°ë¡ '],
                'ë¬¸ì œ': ['ê³¼ì œ', 'ì˜ˆì œ', 'ì—°ìŠµë¬¸ì œ', 'ë¬¸í•­'],
                'ê³µì‹': ['ì‹', 'ì •ë¦¬', 'ë²•ì¹™', 'ì›ë¦¬'],
                'ì¦ëª…': ['ë…¼ì¦', 'ì…ì¦', 'í™•ì¸', 'ê²€ì¦'],
                'ê·¸ë˜í”„': ['ë„í‘œ', 'ë„í˜•', 'ì°¨íŠ¸', 'í•¨ìˆ˜'],
                'ë³€ìˆ˜': ['ë¯¸ì§€ìˆ˜', 'ì¸ìˆ˜', 'íŒŒë¼ë¯¸í„°', 'ìš”ì†Œ']
            },
            syntax_patterns=[
                (r'(\w+)ì„ ê³„ì‚°í•˜ë‹¤', r'\1ì„ êµ¬í•˜ë‹¤'),
                (r'(\w+)ì„ êµ¬í•˜ë‹¤', r'\1ì„ ê³„ì‚°í•˜ë‹¤'),
                (r'(\w+)ëŠ” (\w+)ì´ë‹¤', r'\1 = \2'),
                (r'ë§Œì•½ (\w+)ë¼ë©´', r'\1ì¼ ë•Œ'),
                (r'ë”°ë¼ì„œ (\w+)', r'ê·¸ëŸ¬ë¯€ë¡œ \1'),
                (r'(\w+)ë¡œë¶€í„°', r'\1ì—ì„œ')
            ],
            style_preferences={
                'formal_academic': 0.7,
                'semi_formal': 0.2,
                'informal_polite': 0.1
            }
        )
        
        # ê³¼í•™ ë„ë©”ì¸
        self.science_domain = DomainConfig(
            domain_name="science",
            specialized_vocab={
                'ì‹¤í—˜': ['ì‹œí—˜', 'ê²€ì¦', 'í…ŒìŠ¤íŠ¸', 'ë¶„ì„'],
                'ê´€ì°°': ['ê´€ì¸¡', 'í™•ì¸', 'ëª©ê²©', 'ë°œê²¬'],
                'í˜„ìƒ': ['ì‚¬ê±´', 'ìƒí™©', 'ê²½ìš°', 'ì¼'],
                'ì›ì¸': ['ì´ìœ ', 'ê·¼ê±°', 'ìš”ì¸', 'ë°°ê²½'],
                'ê²°ê³¼': ['íš¨ê³¼', 'ì‚°ë¬¼', 'ì˜í–¥', 'ë³€í™”'],
                'ê°€ì„¤': ['ì¶”ì •', 'ì˜ˆìƒ', 'ì¶”ì¸¡', 'ì´ë¡ '],
                'ë²•ì¹™': ['ì›ë¦¬', 'ê·œì¹™', 'ì •ë¦¬', 'ê³µì‹'],
                'ë¬¼ì§ˆ': ['ì¬ë£Œ', 'ì„±ë¶„', 'ìš”ì†Œ', 'í™”í•©ë¬¼']
            },
            syntax_patterns=[
                (r'(\w+)ì„ ê´€ì°°í•˜ë‹¤', r'\1ì„ ì‚´í´ë³´ë‹¤'),
                (r'(\w+)ê°€ ë°œìƒí•˜ë‹¤', r'\1ê°€ ì¼ì–´ë‚˜ë‹¤'),
                (r'(\w+)ì— ì˜í•´', r'\1ë¡œ ì¸í•´'),
                (r'ì‹¤í—˜ ê²°ê³¼', r'ì‹œí—˜ ê²°ê³¼'),
                (r'ì´ë¡ ì ìœ¼ë¡œ', r'ì›ë¦¬ìƒ'),
                (r'ì‹¤ì œë¡œ', r'í˜„ì‹¤ì ìœ¼ë¡œ')
            ],
            style_preferences={
                'formal_academic': 0.8,
                'semi_formal': 0.2
            }
        )
        
        # ì—­ì‚¬ ë„ë©”ì¸
        self.history_domain = DomainConfig(
            domain_name="history",
            specialized_vocab={
                'ì‹œëŒ€': ['ì‹œê¸°', 'ì—°ëŒ€', 'ë•Œ', 'ì‹œì ˆ'],
                'ì™•ì¡°': ['ì¡°', 'ì™•ê°€', 'í™©ì‹¤', 'ì •ê¶Œ'],
                'ì „ìŸ': ['ì‹¸ì›€', 'ì „íˆ¬', 'ë¶„ìŸ', 'ì¶©ëŒ'],
                'ë¬¸í™”': ['ë¬¸ëª…', 'ì „í†µ', 'í’ì†', 'ê´€ìŠµ'],
                'ì •ì¹˜': ['í†µì¹˜', 'í–‰ì •', 'ê¶Œë ¥', 'ì •ë¶€'],
                'ê²½ì œ': ['ì¬ì •', 'ìƒì—…', 'ë¬´ì—­', 'ì‚°ì—…'],
                'ì¢…êµ': ['ì‹ ì•™', 'ë¯¿ìŒ', 'ì‚¬ìƒ', 'êµë¦¬'],
                'ì‚¬íšŒ': ['ê³µë™ì²´', 'ê³„ì¸µ', 'ì‹ ë¶„', 'ì§‘ë‹¨']
            },
            syntax_patterns=[
                (r'(\w+) ì‹œëŒ€ì—', r'\1 ë•Œì—'),
                (r'(\w+)ê°€ ì¼ì–´ë‚¬ë‹¤', r'\1ê°€ ë°œìƒí–ˆë‹¤'),
                (r'ê·¸ ë‹¹ì‹œ', r'ê·¸ ì‹œëŒ€ì—'),
                (r'ì—­ì‚¬ì ìœ¼ë¡œ', r'ê³¼ê±°ì—'),
                (r'ì „í†µì ìœ¼ë¡œ', r'ì˜›ë¶€í„°'),
                (r'ê³ ëŒ€ë¶€í„°', r'ì˜›ë‚ ë¶€í„°')
            ],
            style_preferences={
                'formal_academic': 0.6,
                'semi_formal': 0.3,
                'informal_polite': 0.1
            }
        )
    
    def initialize_mathematical_patterns(self):
        """ìˆ˜í•™ ë¬¸ì œ íŠ¹í™” íŒ¨í„´"""
        
        self.math_expression_patterns = {
            # ìˆ˜ì‹ í‘œí˜„ ë‹¤ì–‘í™”
            'equation_variants': {
                r'(\w+) = (\w+)': [r'\1ëŠ” \2ì´ë‹¤', r'\1ì™€ \2ëŠ” ê°™ë‹¤', r'\1ëŠ” \2ì™€ ê°™ë‹¤'],
                r'(\w+) > (\w+)': [r'\1ëŠ” \2ë³´ë‹¤ í¬ë‹¤', r'\1ê°€ \2ë¥¼ ì´ˆê³¼í•œë‹¤'],
                r'(\w+) < (\w+)': [r'\1ëŠ” \2ë³´ë‹¤ ì‘ë‹¤', r'\1ê°€ \2ì— ë¯¸ì¹˜ì§€ ëª»í•œë‹¤'],
                r'(\w+) + (\w+)': [r'\1ì™€ \2ì˜ í•©', r'\1ì— \2ë¥¼ ë”í•œ ê²ƒ'],
                r'(\w+) - (\w+)': [r'\1ì—ì„œ \2ë¥¼ ëº€ ê²ƒ', r'\1ì™€ \2ì˜ ì°¨']
            },
            
            # ìˆ˜í•™ì  ë…¼ë¦¬ í‘œí˜„
            'logical_expressions': {
                'ë§Œì•½ ~ë¼ë©´': ['~ì¼ ë•Œ', '~ì¸ ê²½ìš°', '~ë¼ê³  ê°€ì •í•˜ë©´', '~ë¼ê³  í•˜ë©´'],
                'ë”°ë¼ì„œ': ['ê·¸ëŸ¬ë¯€ë¡œ', 'ê³ ë¡œ', 'ì¦‰', 'ê²°êµ­'],
                'ë°˜ëŒ€ë¡œ': ['ê±°ê¾¸ë¡œ', 'ë°˜ë©´ì—', 'í•œí¸', 'ë‹¤ì‹œ ë§í•´'],
                'ì˜ˆë¥¼ ë“¤ì–´': ['ê°€ë ¹', 'ì‹¤ë¡€ë¡œ', 'êµ¬ì²´ì ìœ¼ë¡œ', 'ì¦‰']
            },
            
            # ë¬¸ì œ í•´ê²° ê³¼ì • í‘œí˜„
            'solution_process': {
                'ì²« ë²ˆì§¸ë¡œ': ['ë¨¼ì €', 'ìš°ì„ ', 'ì‹œì‘ìœ¼ë¡œ', 'ì²«ì§¸'],
                'ë‘ ë²ˆì§¸ë¡œ': ['ë‹¤ìŒìœ¼ë¡œ', 'ê·¸ ë‹¤ìŒ', 'ë‘˜ì§¸', 'ì´ì–´ì„œ'],
                'ë§ˆì§€ë§‰ìœ¼ë¡œ': ['ëìœ¼ë¡œ', 'ê²°ë¡ ì ìœ¼ë¡œ', 'ìµœì¢…ì ìœ¼ë¡œ', 'ì…‹ì§¸'],
                'ë‹¨ê³„ë³„ë¡œ': ['ìˆœì„œëŒ€ë¡œ', 'ì°¨ë¡€ë¡œ', 'ê³¼ì •ë³„ë¡œ', 'ìˆœì°¨ì ìœ¼ë¡œ']
            }
        }
    
    def apply_syntactic_transformation(self, text: str, transformation_type: str = 'random') -> List[str]:
        """êµ¬ë¬¸ ë³€í™˜ ì ìš©"""
        variants = []
        
        # ToW í† í° ë³´ì¡´
        tow_pattern = r'<ToW>(.*?)</ToW>'
        tow_tokens = [(m.start(), m.end(), m.group(1)) for m in re.finditer(tow_pattern, text, re.DOTALL)]
        base_text = re.sub(tow_pattern, '', text, flags=re.DOTALL)
        
        if transformation_type == 'random':
            # ëª¨ë“  ë³€í™˜ ì¤‘ ëœë¤ ì„ íƒ
            all_patterns = []
            for pattern_group in [self.voice_patterns, self.constituent_reordering, self.clause_transformation]:
                for patterns in pattern_group.values():
                    all_patterns.extend(patterns)
            
            random.shuffle(all_patterns)
            
            for pattern, replacement in all_patterns[:3]:  # ìµœëŒ€ 3ê°œ ì‹œë„
                if re.search(pattern, base_text):
                    modified = re.sub(pattern, replacement, base_text, count=1)
                    
                    # ToW í† í° ì¬ì‚½ì…
                    for start_pos, end_pos, content in reversed(tow_tokens):
                        relative_pos = start_pos / len(text)
                        insert_pos = int(len(modified) * relative_pos)
                        tow_token = f"<ToW>{content}</ToW>"
                        modified = modified[:insert_pos] + tow_token + modified[insert_pos:]
                    
                    if modified != text:
                        variants.append(modified)
                        break
        
        return variants
    
    def apply_stylistic_transformation(self, text: str, target_style: str = 'random') -> List[str]:
        """ë¬¸ì²´ ë³€í™˜ ì ìš©"""
        variants = []
        
        # ToW í† í° ë³´ì¡´
        tow_pattern = r'<ToW>(.*?)</ToW>'
        tow_tokens = [(m.start(), m.end(), m.group(1)) for m in re.finditer(tow_pattern, text, re.DOTALL)]
        base_text = re.sub(tow_pattern, '', text, flags=re.DOTALL)
        
        if target_style == 'random':
            target_style = random.choice(list(self.formality_patterns.keys()))
        
        if target_style in self.formality_patterns:
            style_config = self.formality_patterns[target_style]
            modified = base_text
            
            # ê¸°ë³¸ ì–´ë¯¸ ë³€í™˜
            for original, transformed in style_config.items():
                if original != 'transforms' and original in modified:
                    modified = modified.replace(original, transformed)
            
            # ì¶”ê°€ ë³€í™˜ ì ìš©
            if 'transforms' in style_config:
                for original, transformed in style_config['transforms'].items():
                    if original in modified:
                        modified = modified.replace(original, transformed)
            
            # ë‹´í™” í‘œì§€ì–´ ì¶”ê°€ (20% í™•ë¥ )
            if random.random() < 0.2:
                marker_type = random.choice(list(self.discourse_markers.keys()))
                marker = random.choice(self.discourse_markers[marker_type])
                sentences = modified.split('.')
                if len(sentences) > 1:
                    sentences[1] = f" {marker} " + sentences[1].strip()
                    modified = '.'.join(sentences)
            
            # ToW í† í° ì¬ì‚½ì…
            if modified != base_text:
                for start_pos, end_pos, content in reversed(tow_tokens):
                    relative_pos = start_pos / len(text)
                    insert_pos = int(len(modified) * relative_pos)
                    tow_token = f"<ToW>{content}</ToW>"
                    modified = modified[:insert_pos] + tow_token + modified[insert_pos:]
                
                variants.append(modified)
        
        return variants
    
    def apply_domain_specialization(self, text: str, domain: str = 'mathematics') -> List[str]:
        """ë„ë©”ì¸ë³„ íŠ¹í™” ì¦ê°•"""
        variants = []
        
        # ë„ë©”ì¸ ì„¤ì • ì„ íƒ
        domain_config = None
        if domain == 'mathematics':
            domain_config = self.math_domain
        elif domain == 'science':
            domain_config = self.science_domain
        elif domain == 'history':
            domain_config = self.history_domain
        
        if not domain_config:
            return variants
        
        # ToW í† í° ë³´ì¡´
        tow_pattern = r'<ToW>(.*?)</ToW>'
        tow_tokens = [(m.start(), m.end(), m.group(1)) for m in re.finditer(tow_pattern, text, re.DOTALL)]
        base_text = re.sub(tow_pattern, '', text, flags=re.DOTALL)
        
        # ì „ë¬¸ ìš©ì–´ êµì²´
        modified = base_text
        for original, alternatives in domain_config.specialized_vocab.items():
            if original in modified:
                alternative = random.choice(alternatives)
                modified = modified.replace(original, alternative, 1)
                break
        
        # ë„ë©”ì¸ íŠ¹í™” êµ¬ë¬¸ íŒ¨í„´ ì ìš©
        if modified == base_text:  # ìš©ì–´ êµì²´ê°€ ì—†ì—ˆë‹¤ë©´ êµ¬ë¬¸ ë³€í™˜
            for pattern, replacement in domain_config.syntax_patterns:
                if re.search(pattern, modified):
                    modified = re.sub(pattern, replacement, modified, count=1)
                    break
        
        # ìˆ˜í•™ ë„ë©”ì¸ íŠ¹í™” ì²˜ë¦¬
        if domain == 'mathematics' and modified == base_text:
            # ìˆ˜ì‹ í‘œí˜„ ë‹¤ì–‘í™”
            for pattern, replacements in self.math_expression_patterns['equation_variants'].items():
                if re.search(pattern, modified):
                    replacement = random.choice(replacements)
                    modified = re.sub(pattern, replacement, modified, count=1)
                    break
        
        # ToW í† í° ì¬ì‚½ì…
        if modified != base_text:
            for start_pos, end_pos, content in reversed(tow_tokens):
                relative_pos = start_pos / len(text)
                insert_pos = int(len(modified) * relative_pos)
                tow_token = f"<ToW>{content}</ToW>"
                modified = modified[:insert_pos] + tow_token + modified[insert_pos:]
            
            variants.append(modified)
        
        return variants
    
    def apply_modality_variation(self, text: str) -> List[str]:
        """ì–‘ìƒì„± í‘œí˜„ ë³€í˜•"""
        variants = []
        
        # ToW í† í° ë³´ì¡´
        tow_pattern = r'<ToW>(.*?)</ToW>'
        tow_tokens = [(m.start(), m.end(), m.group(1)) for m in re.finditer(tow_pattern, text, re.DOTALL)]
        base_text = re.sub(tow_pattern, '', text, flags=re.DOTALL)
        
        # ì–‘ìƒì„± í‘œí˜„ ì¶”ê°€/ë³€ê²½
        modality_type = random.choice(['certainty', 'possibility', 'necessity'])
        level = random.choice(['high', 'medium', 'low'])
        
        if modality_type in self.modality_patterns and level in self.modality_patterns[modality_type]:
            expressions = self.modality_patterns[modality_type][level]
            expression = random.choice(expressions)
            
            # ë¬¸ì¥ ì‹œì‘ì— ì–‘ìƒì„± í‘œí˜„ ì¶”ê°€
            sentences = base_text.split('.')
            if sentences:
                first_sentence = sentences[0].strip()
                if first_sentence:
                    sentences[0] = f" {expression} " + first_sentence
                    modified = '.'.join(sentences)
                    
                    # ToW í† í° ì¬ì‚½ì…
                    for start_pos, end_pos, content in reversed(tow_tokens):
                        relative_pos = start_pos / len(text)
                        insert_pos = int(len(modified) * relative_pos)
                        tow_token = f"<ToW>{content}</ToW>"
                        modified = modified[:insert_pos] + tow_token + modified[insert_pos:]
                    
                    variants.append(modified)
        
        return variants
    
    def generate_advanced_variants(self, text: str, domain: str = 'general') -> List[str]:
        """ê³ ê¸‰ ë³€í˜• ì¢…í•© ìƒì„±"""
        all_variants = []
        
        # 1. êµ¬ë¬¸ ë³€í™˜
        syntactic_variants = self.apply_syntactic_transformation(text)
        all_variants.extend(syntactic_variants)
        
        # 2. ë¬¸ì²´ ë³€í™˜
        stylistic_variants = self.apply_stylistic_transformation(text)
        all_variants.extend(stylistic_variants)
        
        # 3. ë„ë©”ì¸ íŠ¹í™”
        if domain in ['mathematics', 'science', 'history']:
            domain_variants = self.apply_domain_specialization(text, domain)
            all_variants.extend(domain_variants)
        
        # 4. ì–‘ìƒì„± ë³€í˜•
        modality_variants = self.apply_modality_variation(text)
        all_variants.extend(modality_variants)
        
        # ì¤‘ë³µ ì œê±°
        unique_variants = []
        for variant in all_variants:
            if variant not in unique_variants and variant != text:
                unique_variants.append(variant)
        
        return unique_variants[:6]  # ìµœëŒ€ 6ê°œ ë³€í˜• ë°˜í™˜

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logging.basicConfig(level=logging.INFO)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        {
            'text': "í•™ìƒì´ ìˆ˜í•™ ë¬¸ì œë¥¼ <ToW>Mathematical reasoning required</ToW> í‘¼ë‹¤. ì´ ë°©ë²•ì€ ë§¤ìš° íš¨ê³¼ì ì´ë‹¤.",
            'domain': 'mathematics'
        },
        {
            'text': "ê³¼í•™ìê°€ ì‹¤í—˜ì„ <ToW>Scientific methodology needed</ToW> ì§„í–‰í•œë‹¤. ê²°ê³¼ë¥¼ ê´€ì°°í•œë‹¤.",
            'domain': 'science'
        },
        {
            'text': "ì¡°ì„  ì‹œëŒ€ì— <ToW>Historical context important</ToW> ë¬¸í™”ê°€ ë°œë‹¬í–ˆë‹¤. ì „í†µì´ ì¤‘ìš”í–ˆë‹¤.",
            'domain': 'history'
        }
    ]
    
    engine = AdvancedAugmentationEngine()
    
    print("ğŸš€ Advanced Augmentation Techniques í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for i, case in enumerate(test_cases, 1):
        text = case['text']
        domain = case['domain']
        
        print(f"\n{i}. {domain.upper()} ë„ë©”ì¸")
        print(f"ì›ë³¸: {text}")
        
        variants = engine.generate_advanced_variants(text, domain)
        
        print(f"ìƒì„±ëœ ê³ ê¸‰ ë³€í˜• {len(variants)}ê°œ:")
        for j, variant in enumerate(variants, 1):
            print(f"  {j}. {variant}")
        
        print("-" * 50)

if __name__ == "__main__":
    main()