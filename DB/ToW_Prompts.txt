##Prompt for Thought Generation ##

Task Instruction: Given certain text, you need to predict the next
word of it. Moreover, before your output, you could first give short
thoughts about how you infer the next word based on the provided
context.
Here are five examples for the task:
Example 0: {"우리는 가끔 온라인 쿠폰과 기타 특별 혜택을 제공합니다. <hCoT> Customers can explore additional ways to find deals beyond online coupons, like subscribing. </hCoT> 또는 제품 연구에 참여하고 싶다면 '홈 제품 배치'를 체크하고 몇 가지 질문에 답해주세요. 무엇을 기다리고 있나요?"}
Example 1: {"방정식 2x + 5 = 17을 풀어보세요. 먼저 양변에서 5를 <hCoT> The context presents an equation 2x + 5 = 17 and mentions subtracting 5 from both sides, so the next word should be '빼면' to describe the subtraction operation. </hCoT> 빼면 2x = 12가 됩니다. 그 다음 양변을 2로 <hCoT> The context shows 2x = 12 and mentions dividing both sides by 2, so the next word should be '나누면' to complete the division step. </hCoT> 나누면 x = 6이 답입니다.\"}"        "Example 2: {\"Unity에서 2D 객체를 드래그할 때 다른 객체와의 최소 거리는 1.5f입니다. 두 객체가 <hCoT> The context describes distance constraints for 2D objects in Unity, so the next word should be '연결되면' to describe what happens when objects connect. </hCoT> 연결되면 드래그가 더 제한됩니다."}
Example 2: {"Unity에서 2D 객체를 드래그할 때 다른 객체와의 최소 거리는 1.5f입니다. 두 객체가 <hCoT> The context describes distance constraints for 2D objects in Unity, so the next word should be '연결되면' to describe what happens when objects connect. </hCoT> 연결되면 드래그가 더 제한됩니다."}
Example 3: {"대수학에서 대체는 문자를 숫자로 바꾸는 것입니다. 숫자와 <hCoT> The context explains algebraic substitution involving numbers, so the next word should be '문자' as algebra deals with both numbers and variables. </hCoT> 문자 사이에는 곱셈 기호가 숨겨져 있습니다."}
Example 4: {"랜달즈빌 이사 회사 Movers MAX 디렉토리는 <hCoT> The context introduces a moving company directory called Movers MAX, so the next word should be '이사' to specify what kind of resources this directory provides. </hCoT> 이사 자원을 위한 원스톱 소스입니다."}
Now please give me your prediction for the thought and next word based on the following context:
{그는 KCBS 바비큐 대회에 참가하는 데 필요한 모든 것, 즉 기술, 레시피, 일정, 육류 선택 및 손질법, 그리고 스모커 및 불에 대한 }

Thought
Next Word:

##Prompt for Thought Generation ## 한줄짜리 
Task Instruction: Given certain text, you need to predict the next word of it. Moreover, before your output, you could first give short thoughts about how you infer the next word based on the provided context.\nHere are five examples for the task:\nExample 0: {"우리는 가끔 온라인 쿠폰과 기타 특별 혜택을 제공합니다. <hCoT> Customers can explore additional ways to find deals beyond online coupons, like subscribing. </hCoT> 또는 제품 연구에 참여하고 싶다면 '홈 제품 배치'를 체크하고 몇 가지 질문에 답해주세요. 무엇을 기다리고 있나요?"}\n\nExample 1: {"방정식 2x + 5 = 17을 풀어보세요. 먼저 양변에서 5를 <hCoT> The context presents an equation 2x + 5 = 17 and mentions subtracting 5 from both sides, so the next word should be '빼면' to describe the subtraction operation. </hCoT> 빼면 2x = 12가 됩니다. 그 다음 양변을 2로 <hCoT> The context shows 2x = 12 and mentions dividing both sides by 2, so the next word should be '나누면' to complete the division step. </hCoT> 나누면 x = 6이 답입니다.\"}"        "Example 2: {\"Unity에서 2D 객체를 드래그할 때 다른 객체와의 최소 거리는 1.5f입니다. 두 객체가 <hCoT> The context describes distance constraints for 2D objects in Unity, so the next word should be '연결되면' to describe what happens when objects connect. </hCoT> 연결되면 드래그가 더 제한됩니다."}\n\nExample 2: {"Unity에서 2D 객체를 드래그할 때 다른 객체와의 최소 거리는 1.5f입니다. 두 객체가 <hCoT> The context describes distance constraints for 2D objects in Unity, so the next word should be '연결되면' to describe what happens when objects connect. </hCoT> 연결되면 드래그가 더 제한됩니다."}\n\nExample 3: {"대수학에서 대체는 문자를 숫자로 바꾸는 것입니다. 숫자와 <hCoT> The context explains algebraic substitution involving numbers, so the next word should be '문자' as algebra deals with both numbers and variables. </hCoT> 문자 사이에는 곱셈 기호가 숨겨져 있습니다."}\n\nExample 4: {"랜달즈빌 이사 회사 Movers MAX 디렉토리는 <hCoT> The context introduces a moving company directory called Movers MAX, so the next word should be '이사' to specify what kind of resources this directory provides. </hCoT> 이사 자원을 위한 원스톱 소스입니다."}\n\nNow please give me your prediction for the thought and next word based on the following context:\n\n{그는 KCBS 바비큐 대회에 참가하는 데 필요한 모든 것, 즉 기술, 레시피, 일정, 육류 선택 및 손질법, 그리고 스모커 및 불에 대한 }\n\nThought:\nNext Word:

## Prompt for Consistency Check ##
Task Instruction: Given the following certain text, thought for its
next word and the gold next word, you need to judge whether the
thought for generating the next word is consistent based on the
reasoning process and the given text. For consistency, we mean that
the thought only needs to generally entail the gold next word in
reasoning and does NOT need to be specific on the gold next words.
Context: {"드라이브 복제는 먼저 부팅 가능한 Apple 등과 같은 "}
Thought: {"The context states \"드라이브 복제는 먼저 부팅 가능한 Apple 등과 같은 \" which translates to \"Drive cloning first [is done by/starts with] a bootable [something] such as Apple's, etc.\". The phrase \"부팅 가능한\" (bootable) modifies the noun to be predicted. \"Apple 등과 같은\" (such as Apple's, or similar to Apple's) further specifies this noun. In the context of Apple systems and drive cloning, a common bootable medium is an installation disk (or USB drive, which is a type of disk) or a recovery disk. Therefore, \"디스크\" (disk) is a logical completion, referring to a bootable disk like an Apple-provided one (e.g., macOS installer) or similar."}
Gold Next Word: {"방식으로"}
Now please give me your single reasoning and judgement, i.e. True or
False, for the consistency of thought and gold next word based on
the above information.
Reasoning: Let’s think step by step.
Judgement:


## Prompt for Summarization Prompt (exact match words) ##
Task Instruction: Please modify the following thought into a shorter
one within 15 words without changing much of the meaning. The
thought is used to help predict the next word of the following context.
Context: {<context>}
Thought: {<thought>}
Shorter Thought:


## Prompt for Summarization and Denoising Prompt (soft consistent words) ##
Task Instruction: Please modify the following thought into a shorter
one within 15 words without changing much of the meaning. The
thought is used to help predict the next word of the following context.
Besides, the gold next word is also given. You should try to shorten
the thought based on it.
Context: {<context>}
Thought: {<thought>}
Gold Next Word: {<gold_next>}
Shorter Thought:
