#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Option 2: Pure Original TOW Implementation - Usage Example
=========================================================

This script demonstrates how to use the Option 2 TOW system which implements:
- Data Augmentation Pipeline for training corpus enhancement
- Token Classification (trivial/exact/soft/unpredictable) 
- Cross-lingual TOW with English-only thoughts
- Training dataset generation with proper <ToW> formatting

Example Usage:
    python examples/option2_tow_usage.py --input_file data.txt --output_file tow_dataset.jsonl
"""

import sys
import os
import argparse
import logging
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tow_architecture.core.thought_processor import ThoughtTokenProcessor
from tow_architecture.core.token_classifier import TokenClassifier, ClassificationContext
from tow_architecture.core.cross_lingual_tow import CrossLingualTOWSystem, CrossLingualContext
from tow_architecture.data_augmentation.pipeline import TOWDataAugmentationPipeline
from tow_architecture.models.base_adapter import BaseModelAdapter
from tow_architecture.utils.config import get_development_config, get_production_config
from tow_architecture.utils.text_utils import sanitize_tow_token
from tow_architecture.utils.logger import get_logger

logger = get_logger(__name__)


class MockModelAdapter(BaseModelAdapter):
    """
    Mock model adapter for demonstration purposes.
    In production, replace with actual model adapters (DeepSeek, Llama, Qwen).
    """
    
    def generate(self, prompt: str, max_tokens: int = 100, temperature: float = 0.7, **kwargs) -> str:
        """Mock generation - in production use actual model"""
        # Simple mock responses for demonstration
        if "ÏàòÌïô" in prompt or "math" in prompt:
            return "equation calculation formula"
        elif "ÌîÑÎ°úÍ∑∏Îû®" in prompt or "program" in prompt:
            return "code function algorithm"
        elif "ÏöîÎ¶¨" in prompt or "cooking" in prompt:
            return "ingredient recipe method"
        else:
            return "analysis context reasoning"
    
    def get_model_info(self) -> dict:
        return {"model_name": "MockModel", "version": "1.0"}


def demonstrate_token_classification():
    """Demonstrate token classification functionality"""
    print("\n" + "="*60)
    print("üè∑Ô∏è  Token Classification Demonstration")
    print("="*60)
    
    classifier = TokenClassifier(language="ko")
    
    # Test cases for different categories
    test_cases = [
        # (context, predicted, actual) tuples
        ("Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ï†ïÎßê", "Ï¢ãÎã§", "Ï¢ãÎÑ§Ïöî"),      # Soft consistent
        ("ÏïàÎÖïÌïòÏÑ∏Ïöî. Ï†Ä", "Îäî", "Îäî"),              # Exact match
        ("ÌååÏù¥Ïç¨ÏóêÏÑú Ìï®ÏàòÎ•º Ï†ïÏùòÌï† Îïå", "def", "def"),  # Exact match
        ("Í∑∏Îäî Ïñ¥Ï†ú", "ÌïôÍµêÏóê", "Î≥ëÏõêÏóê"),            # Unpredictable
        ("ÎÇòÎäî", "ÎÑàÎ•º", "ÏùÑ"),                      # Trivial (particle)
    ]
    
    for context, predicted, actual in test_cases:
        classification_context = ClassificationContext(
            preceding_text=context,
            predicted_token=predicted,
            actual_token=actual,
            language="ko"
        )
        
        result = classifier.classify_token(classification_context)
        
        print(f"\nüìù Context: {context}")
        print(f"üéØ Predicted: '{predicted}' ‚Üí Actual: '{actual}'")
        print(f"üè∑Ô∏è  Category: {result.category.value}")
        print(f"üìä Confidence: {result.confidence:.3f}")
        print(f"üí≠ Reasoning: {result.reasoning}")


def demonstrate_cross_lingual_tow():
    """Demonstrate cross-lingual TOW generation"""
    print("\n" + "="*60)
    print("üåç Cross-lingual TOW Demonstration")
    print("="*60)
    
    model_adapter = MockModelAdapter()
    cross_lingual_system = CrossLingualTOWSystem(model_adapter)
    
    # Test cases for different languages
    test_cases = [
        {
            "text": "Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ï†ïÎßê Ï¢ãÏïÑÏÑú ÏÇ∞Ï±ÖÏùÑ",
            "language": "ko",
            "predicted": "ÌñàÎã§",
            "actual": "ÌïòÍ≥†Ïã∂Îã§",
            "category": "soft_consistent"
        },
        {
            "text": "ÌååÏù¥Ïç¨ ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏóêÏÑú Í∞ÄÏû• Ï§ëÏöîÌïú Í≤ÉÏùÄ",
            "language": "ko", 
            "predicted": "Î¨∏Î≤ï",
            "actual": "Î°úÏßÅ",
            "category": "unpredictable"
        },
        {
            "text": "‰ªäÂ§©Â§©Ê∞îÂæàÂ•ΩÔºåÊàëÊÉ≥Âéª",
            "language": "zh",
            "predicted": "ÂÖ¨Âõ≠",
            "actual": "Êï£Ê≠•",
            "category": "soft_consistent"
        }
    ]
    
    for case in test_cases:
        context = CrossLingualContext(
            source_text=case["text"],
            source_language=case["language"],
            target_word=case["actual"],
            predicted_word=case["predicted"],
            reasoning_type=case["category"]
        )
        
        tow_token = cross_lingual_system.generate_english_tow(context)
        
        print(f"\nüìù Source ({case['language']}): {case['text']}")
        print(f"üéØ Predicted: '{case['predicted']}' ‚Üí Actual: '{case['actual']}'")
        print(f"üè∑Ô∏è  Category: {case['category']}")
        print(f"üß† English TOW: {tow_token}")


def demonstrate_thought_processor():
    """Demonstrate enhanced thought processor"""
    print("\n" + "="*60)
    print("üß† Thought Processor Demonstration (Option 2)")
    print("="*60)
    
    model_adapter = MockModelAdapter()
    processor = ThoughtTokenProcessor(model_adapter, language="ko")
    
    # Test texts
    test_texts = [
        "ÏàòÌïôÏóêÏÑú Î∞©Ï†ïÏãù 2x + 5 = 17ÏùÑ ÌíÄÎ©¥",
        "ÌååÏù¥Ïç¨ÏóêÏÑú Î¶¨Ïä§Ìä∏Î•º ÏÉùÏÑ±ÌïòÎ†§Î©¥ ÎåÄÍ¥ÑÌò∏Î•º ÏÇ¨Ïö©ÌïòÏó¨",
        "Ïò§Îäò ÎÇ†Ïî®Í∞Ä ÎßëÏïÑÏÑú Í≥µÏõêÏóêÏÑú ÏÇ∞Ï±ÖÏùÑ"
    ]
    
    for text in test_texts:
        print(f"\nüìù Input Text: {text}")
        
        # Generate standard thoughts
        thoughts = processor.generate_thoughts(text, max_thoughts=3)
        print(f"üß† Generated TOW Tokens:")
        for i, thought in enumerate(thoughts, 1):
            print(f"   {i}. {thought}")
        
        # Generate classified thoughts (simulation)
        words = text.split()
        if len(words) > 2:
            predicted_words = ["Îã§ÏùåÎã®Ïñ¥"]  # Mock prediction
            actual_words = [words[-1]]      # Last word as actual
            
            classified_results = processor.generate_classified_thoughts(
                text=" ".join(words[:-1]),
                predicted_words=predicted_words,
                actual_words=actual_words
            )
            
            if classified_results:
                result = classified_results[0]
                print(f"üè∑Ô∏è  Classification: {result['category']}")
                print(f"üìä Confidence: {result['confidence']:.3f}")
                print(f"üåç Cross-lingual TOW: {result['tow_token']}")


def demonstrate_data_augmentation_pipeline():
    """Demonstrate data augmentation pipeline"""
    print("\n" + "="*60)
    print("üîÑ Data Augmentation Pipeline Demonstration")
    print("="*60)
    
    model_adapter = MockModelAdapter()
    pipeline = TOWDataAugmentationPipeline(model_adapter, language="ko")
    
    # Sample input data
    input_texts = [
        "ÌïúÍµ≠Ïùò Ï†ÑÌÜµ ÏùåÏãù Ï§ë ÍπÄÏπòÎäî Î∞úÌö® ÏùåÏãùÏúºÎ°ú Í±¥Í∞ïÏóê Ï¢ãÏäµÎãàÎã§.",
        "ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏóêÏÑú ÏïåÍ≥†Î¶¨Ï¶òÏùÄ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî Ï†àÏ∞®Ï†Å Î∞©Î≤ïÏûÖÎãàÎã§.",
        "Í∏∞Í≥ÑÌïôÏäµÏùÄ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ìå®ÌÑ¥ÏùÑ Ï∞æÏïÑ ÏòàÏ∏°ÌïòÎäî Í∏∞Ïà†ÏûÖÎãàÎã§.",
        "Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ï¢ãÏïÑÏÑú ÏπúÍµ¨Îì§Í≥º Í≥µÏõêÏóêÏÑú ÌîºÌÅ¨ÎãâÏùÑ ÌñàÏäµÎãàÎã§.",
        "ÏàòÌïôÏóêÏÑú ÎØ∏Ï†ÅÎ∂ÑÏùÄ Î≥ÄÌôîÏú®ÏùÑ Îã§Î£®Îäî Ï§ëÏöîÌïú Î∂ÑÏïºÏûÖÎãàÎã§."
    ]
    
    print(f"üìä Processing {len(input_texts)} input texts...")
    
    # Process corpus (small batch for demo)
    output_path = "demo_tow_dataset.jsonl"
    stats = pipeline.process_corpus(
        input_data=input_texts,
        output_path=output_path,
        batch_size=5,
        max_workers=2
    )
    
    print(f"\nüìà Processing Statistics:")
    print(f"   ‚Ä¢ Total processed: {stats.total_processed}")
    print(f"   ‚Ä¢ Successful generations: {stats.successful_generations}")
    print(f"   ‚Ä¢ Failed generations: {stats.failed_generations}")
    print(f"   ‚Ä¢ Processing time: {stats.processing_time:.2f}s")
    print(f"   ‚Ä¢ Average confidence: {stats.average_confidence:.3f}")
    
    print(f"\nüìä Category Distribution:")
    for category, count in stats.category_counts.items():
        print(f"   ‚Ä¢ {category}: {count}")
    
    if os.path.exists(output_path):
        print(f"\n‚úÖ Dataset saved to: {output_path}")
        
        # Show sample entries
        import json
        print(f"\nüìã Sample TOW Entries:")
        with open(output_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= 3:  # Show first 3 entries
                    break
                entry = json.loads(line)
                print(f"\n   Entry {i+1}:")
                print(f"   ‚Ä¢ Context: {entry['context']}")
                print(f"   ‚Ä¢ Actual word: {entry['actual_token']}")
                print(f"   ‚Ä¢ TOW token: {sanitize_tow_token(entry['thought_token'])}")
                print(f"   ‚Ä¢ Category: {entry['category']}")
    
    # Cleanup demo file
    if os.path.exists(output_path):
        os.remove(output_path)


def main():
    """Main demonstration function"""
    parser = argparse.ArgumentParser(description="Option 2 TOW System Demonstration")
    parser.add_argument("--demo", choices=["all", "classification", "cross_lingual", "thoughts", "pipeline"],
                       default="all", help="Which demonstration to run")
    parser.add_argument("--input_file", type=str, help="Input file for processing")
    parser.add_argument("--output_file", type=str, help="Output file for TOW dataset")
    parser.add_argument("--language", type=str, default="ko", help="Source language")
    parser.add_argument("--config", choices=["development", "production"], default="development",
                       help="Configuration preset to use")
    
    args = parser.parse_args()
    
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("üöÄ Option 2: Pure Original TOW Implementation")
    print("=" * 60)
    print("Features:")
    print("‚Ä¢ Data Augmentation Pipeline for training corpus enhancement")
    print("‚Ä¢ Token Classification (trivial/exact/soft/unpredictable)")
    print("‚Ä¢ Cross-lingual TOW with English-only thoughts")
    print("‚Ä¢ Training dataset generation with <ToW> formatting")
    print("‚Ä¢ Token format consistency with original paper")
    
    # Get configuration
    if args.config == "production":
        config = get_production_config()
        print(f"\nüîß Using production configuration")
    else:
        config = get_development_config()
        print(f"\nüîß Using development configuration")
    
    config.language = args.language
    config.validate()
    
    try:
        # Run demonstrations
        if args.demo in ["all", "classification"]:
            demonstrate_token_classification()
        
        if args.demo in ["all", "cross_lingual"]:
            demonstrate_cross_lingual_tow()
        
        if args.demo in ["all", "thoughts"]:
            demonstrate_thought_processor()
        
        if args.demo in ["all", "pipeline"]:
            demonstrate_data_augmentation_pipeline()
        
        # Process input file if provided
        if args.input_file and args.output_file:
            print("\n" + "="*60)
            print("üìÅ Processing Input File")
            print("="*60)
            
            if not os.path.exists(args.input_file):
                print(f"‚ùå Input file not found: {args.input_file}")
                return
            
            model_adapter = MockModelAdapter()
            pipeline = TOWDataAugmentationPipeline(model_adapter, language=args.language)
            
            print(f"üìÇ Processing file: {args.input_file}")
            stats = pipeline.process_file(args.input_file, args.output_file)
            
            print(f"\n‚úÖ Processing completed!")
            print(f"üìä Generated {stats.successful_generations} TOW entries")
            print(f"üíæ Saved to: {args.output_file}")
        
        print("\n" + "="*60)
        print("üéâ Option 2 TOW Demonstration Completed Successfully!")
        print("="*60)
        print("\nNext Steps:")
        print("‚Ä¢ Replace MockModelAdapter with actual model (DeepSeek/Llama/Qwen)")
        print("‚Ä¢ Train models using generated TOW datasets")
        print("‚Ä¢ Fine-tune classification thresholds based on your data")
        print("‚Ä¢ Scale up processing for larger corpora")
        print("‚Ä¢ Integrate with your MLOps pipeline")
        
    except Exception as e:
        logger.error(f"Demonstration failed: {e}")
        print(f"\n‚ùå Error: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
