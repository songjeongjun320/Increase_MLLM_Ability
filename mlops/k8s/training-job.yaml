# Kubernetes Job for ToW Model Training
apiVersion: batch/v1
kind: Job
metadata:
  name: tow-training-job
  namespace: tow-training
  labels:
    app: tow-training
    version: v1.0.0
    component: training
spec:
  backoffLimit: 3
  ttlSecondsAfterFinished: 86400  # Keep job for 24 hours after completion
  
  template:
    metadata:
      labels:
        app: tow-training
        version: v1.0.0
        component: training
    spec:
      serviceAccountName: tow-training
      restartPolicy: Never
      
      containers:
      - name: tow-training
        image: tow-research/training:v1.0.0
        imagePullPolicy: Always
        
        command: ["/workspace/start-training.sh"]
        
        env:
        - name: MLOPS_ENV
          value: "production"
        - name: AUTO_START_TRAINING
          value: "true"
        - name: CUDA_VISIBLE_DEVICES
          value: "0,1,2,3"  # Use all 4 GPUs
        
        # MLflow configuration
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            configMapKeyRef:
              name: tow-config
              key: mlflow-tracking-uri
        
        # Weights & Biases
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: tow-wandb-secret
              key: api-key
              optional: true
        - name: WANDB_PROJECT
          value: "tow-training-production"
        
        # Training configuration
        - name: TRAINING_CONFIG_FILE
          value: "/workspace/config/training-config.yaml"
        
        resources:
          requests:
            memory: "32Gi"
            cpu: "8000m"
            nvidia.com/gpu: 4
          limits:
            memory: "64Gi"
            cpu: "16000m"
            nvidia.com/gpu: 4
        
        volumeMounts:
        - name: training-data
          mountPath: /workspace/data
          readOnly: true
        - name: model-output
          mountPath: /workspace/models
        - name: training-config
          mountPath: /workspace/config
          readOnly: true
        - name: training-logs
          mountPath: /workspace/logs
        - name: checkpoints
          mountPath: /workspace/checkpoints
        
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false  # Training needs to write checkpoints
      
      volumes:
      - name: training-data
        persistentVolumeClaim:
          claimName: tow-training-data-pvc
      - name: model-output
        persistentVolumeClaim:
          claimName: tow-model-output-pvc
      - name: training-config
        configMap:
          name: tow-training-config
      - name: training-logs
        persistentVolumeClaim:
          claimName: tow-training-logs-pvc
      - name: checkpoints
        persistentVolumeClaim:
          claimName: tow-checkpoints-pvc
      
      nodeSelector:
        node-type: gpu
        gpu-memory: very-high
        gpu-count: "4"
      
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      - key: training
        operator: Exists
        effect: NoSchedule

---
# Distributed Training Job (Multi-node)
apiVersion: batch/v1
kind: Job
metadata:
  name: tow-distributed-training
  namespace: tow-training
  labels:
    app: tow-distributed-training
    version: v1.0.0
    component: training
spec:
  parallelism: 2  # 2 nodes
  completions: 2
  backoffLimit: 3
  ttlSecondsAfterFinished: 86400
  
  template:
    metadata:
      labels:
        app: tow-distributed-training
        version: v1.0.0
        component: training
    spec:
      serviceAccountName: tow-training
      restartPolicy: Never
      
      containers:
      - name: tow-distributed-training
        image: tow-research/training:v1.0.0
        imagePullPolicy: Always
        
        command: ["/workspace/distributed-training.sh"]
        
        env:
        - name: MLOPS_ENV
          value: "production"
        - name: WORLD_SIZE
          value: "8"  # 2 nodes * 4 GPUs each
        - name: NPROC_PER_NODE
          value: "4"
        - name: CUDA_VISIBLE_DEVICES
          value: "0,1,2,3"
        
        # Distributed training coordination
        - name: MASTER_ADDR
          value: "tow-training-master"
        - name: MASTER_PORT
          value: "29500"
        - name: NODE_RANK
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['job-completion-index']
        
        # MLflow and W&B configuration
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            configMapKeyRef:
              name: tow-config
              key: mlflow-tracking-uri
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: tow-wandb-secret
              key: api-key
              optional: true
        - name: WANDB_PROJECT
          value: "tow-distributed-training"
        
        resources:
          requests:
            memory: "64Gi"
            cpu: "16000m"
            nvidia.com/gpu: 4
          limits:
            memory: "128Gi"
            cpu: "32000m"
            nvidia.com/gpu: 4
        
        volumeMounts:
        - name: training-data
          mountPath: /workspace/data
          readOnly: true
        - name: distributed-model-output
          mountPath: /workspace/models
        - name: training-config
          mountPath: /workspace/config
          readOnly: true
        - name: distributed-logs
          mountPath: /workspace/logs
        - name: distributed-checkpoints
          mountPath: /workspace/checkpoints
        
        # Network ports for distributed training
        ports:
        - containerPort: 29500
          name: master-port
        - containerPort: 29501
          name: worker-port
        
      volumes:
      - name: training-data
        persistentVolumeClaim:
          claimName: tow-training-data-pvc
      - name: distributed-model-output
        persistentVolumeClaim:
          claimName: tow-distributed-models-pvc
      - name: training-config
        configMap:
          name: tow-distributed-training-config
      - name: distributed-logs
        persistentVolumeClaim:
          claimName: tow-distributed-logs-pvc
      - name: distributed-checkpoints
        persistentVolumeClaim:
          claimName: tow-distributed-checkpoints-pvc
      
      nodeSelector:
        node-type: gpu
        gpu-memory: very-high
        gpu-count: "4"
      
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      - key: training
        operator: Exists
        effect: NoSchedule

---
# Service for distributed training coordination
apiVersion: v1
kind: Service
metadata:
  name: tow-training-master
  namespace: tow-training
spec:
  type: ClusterIP
  ports:
  - port: 29500
    targetPort: 29500
    name: master-port
  - port: 29501
    targetPort: 29501
    name: worker-port
  selector:
    app: tow-distributed-training

---
# CronJob for scheduled training
apiVersion: batch/v1
kind: CronJob
metadata:
  name: tow-scheduled-training
  namespace: tow-training
  labels:
    app: tow-scheduled-training
    component: training
spec:
  schedule: "0 2 * * 0"  # Weekly at 2 AM Sunday
  jobTemplate:
    spec:
      backoffLimit: 2
      ttlSecondsAfterFinished: 172800  # Keep for 48 hours
      template:
        metadata:
          labels:
            app: tow-scheduled-training
            component: training
        spec:
          serviceAccountName: tow-training
          restartPolicy: Never
          
          containers:
          - name: tow-scheduled-training
            image: tow-research/training:v1.0.0
            imagePullPolicy: Always
            
            command: ["/workspace/start-training.sh"]
            
            env:
            - name: MLOPS_ENV
              value: "production"
            - name: AUTO_START_TRAINING
              value: "true"
            - name: TRAINING_TYPE
              value: "scheduled"
            - name: CUDA_VISIBLE_DEVICES
              value: "0,1,2,3"
            
            # Configuration
            - name: MLFLOW_TRACKING_URI
              valueFrom:
                configMapKeyRef:
                  name: tow-config
                  key: mlflow-tracking-uri
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: tow-wandb-secret
                  key: api-key
                  optional: true
            
            resources:
              requests:
                memory: "32Gi"
                cpu: "8000m"
                nvidia.com/gpu: 4
              limits:
                memory: "64Gi"
                cpu: "16000m"
                nvidia.com/gpu: 4
            
            volumeMounts:
            - name: training-data
              mountPath: /workspace/data
              readOnly: true
            - name: scheduled-model-output
              mountPath: /workspace/models
            - name: training-config
              mountPath: /workspace/config
              readOnly: true
          
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: tow-training-data-pvc
          - name: scheduled-model-output
            persistentVolumeClaim:
              claimName: tow-scheduled-models-pvc
          - name: training-config
            configMap:
              name: tow-training-config
          
          nodeSelector:
            node-type: gpu
            gpu-memory: very-high